{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF 内容清洗分析\n",
    "\n",
    "这个 notebook 用于分析从 PDF 文件中提取的文本内容，并开发启发式规则来过滤掉乱码和低质量的文本块。\n",
    "\n",
    "**目标**: 针对 `Journal of Field Robotics - 2017 - Paolillo - Autonomous car driving by a humanoid robot.pdf` 文件，识别并过滤掉类似 `dy Woy papeo|umog` 这样的错误提取结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\rag_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "import os\n",
    "import re\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for file at: data\\embodia\\pdf\\Journal of Field Robotics - 2017 - Paolillo - Autonomous car driving by a humanoid robot.pdf\n",
      "✅ File found.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = os.path.join(\"data\", \"embodia\", \"pdf\", \"Journal of Field Robotics - 2017 - Paolillo - Autonomous car driving by a humanoid robot.pdf\")\n",
    "\n",
    "print(f\"Checking for file at: {pdf_path}\")\n",
    "if os.path.exists(pdf_path):\n",
    "    print(\"✅ File found.\")\n",
    "else:\n",
    "    print(\"❌ File not found! Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioning PDF... (这可能需要一点时间)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully partitioned PDF into 617 elements.\n"
     ]
    }
   ],
   "source": [
    "# 使用 hi_res策略以获取更好的上下文和结构。\n",
    "# 我们禁用了图像提取，因为我们专注于文本。\n",
    "# 我们启用了表格推断。\n",
    "print(\"Partitioning PDF... (这可能需要一点时间)\")\n",
    "elements = []\n",
    "try:\n",
    "    elements = partition_pdf(\n",
    "        pdf_path,\n",
    "        strategy=\"hi_res\",\n",
    "        extract_images_in_pdf=False,\n",
    "        infer_table_structure=True,\n",
    "        languages=[\"eng\"], # 指定语言以提高解析效果\n",
    "    )\n",
    "    print(f\"✅ Successfully partitioned PDF into {len(elements)} elements.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ An error occurred during partitioning: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 1: 检查 `element` 对象的实际结构\n",
    "\n",
    "`partition_pdf` 返回一个 `Element` 对象列表。为了避免之前的 `KeyError`，我们首先需要检查这些对象的实际数据结构。我们将使用 `.to_dict()` 方法安全地查看其内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting Element Structure ---\n",
      "--- Element 1 (Category: Header) ---\n",
      "{'type': 'Header', 'element_id': '4c77e1b61a4b29a53a2681e922f3f3e0', 'text': 'Received: 10 February 2016', 'metadata': {'detection_class_prob': 0.8243770599365234, 'is_extracted': 'true', 'coordinates': {'points': ((np.float64(129.86666666666667), np.float64(77.83703222222205)), (np.float64(129.86666666666667), np.float64(97.27418518066406)), (np.float64(372.77178955078125), np.float64(97.27418518066406)), (np.float64(372.77178955078125), np.float64(77.83703222222205))), 'system': 'PixelSpace', 'layout_width': 1654, 'layout_height': 2174}, 'last_modified': '2025-05-08T18:56:56', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': 'data\\\\embodia\\\\pdf', 'filename': 'Journal of Field Robotics - 2017 - Paolillo - Autonomous car driving by a humanoid robot.pdf'}}\n",
      " \n",
      "--- Element 2 (Category: Header) ---\n",
      "{'type': 'Header', 'element_id': '87d166be0a8b58cc6f88442bcc7a76d5', 'text': 'Revised: 15 May 2017', 'metadata': {'detection_class_prob': 0.8137696981430054, 'is_extracted': 'true', 'coordinates': {'points': ((np.float64(379.2624206542969), np.float64(74.04351806640625)), (np.float64(379.2624206542969), np.float64(97.39791870117188)), (np.float64(613.9013671875), np.float64(97.39791870117188)), (np.float64(613.9013671875), np.float64(74.04351806640625))), 'system': 'PixelSpace', 'layout_width': 1654, 'layout_height': 2174}, 'last_modified': '2025-05-08T18:56:56', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': 'data\\\\embodia\\\\pdf', 'filename': 'Journal of Field Robotics - 2017 - Paolillo - Autonomous car driving by a humanoid robot.pdf'}}\n",
      " \n",
      "--- Element 3 (Category: Header) ---\n",
      "{'type': 'Header', 'element_id': '9a3f7e219ab0496bd947efee971c9074', 'text': 'Accepted: 24 May 2017', 'metadata': {'detection_class_prob': 0.7028013467788696, 'is_extracted': 'true', 'coordinates': {'points': ((np.float64(635.7975), np.float64(76.22779846191406)), (np.float64(635.7975), np.float64(97.86017608642578)), (np.float64(836.8017876666667), np.float64(97.86017608642578)), (np.float64(836.8017876666667), np.float64(76.22779846191406))), 'system': 'PixelSpace', 'layout_width': 1654, 'layout_height': 2174}, 'last_modified': '2025-05-08T18:56:56', 'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 1, 'file_directory': 'data\\\\embodia\\\\pdf', 'filename': 'Journal of Field Robotics - 2017 - Paolillo - Autonomous car driving by a humanoid robot.pdf'}}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inspecting Element Structure ---\")\n",
    "if elements:\n",
    "    # partition_pdf 的输出是 Element 对象的列表。\n",
    "    # 让我们通过将前3个元素转换为字典来查看它们。\n",
    "    for i, element in enumerate(elements[:3]):\n",
    "        print(f\"--- Element {i+1} (Category: {element.category}) ---\")\n",
    "        # .to_dict() 是查看元素数据的安全方法。\n",
    "        print(element.to_dict())\n",
    "        print(\" \")\n",
    "else:\n",
    "    print(\"No elements were extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 2: 定义用于数据清洗的启发式规则\n",
    "\n",
    "根据观察到的乱码，我们定义一些函数来识别和标记低质量的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Defining Cleaning Functions (with Reasons) ---\n",
      "✅ Corrected cleaning functions defined.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(\"--- Defining Cleaning Functions (with Reasons) ---\")\n",
    "\n",
    "def contains_garbled_patterns(text):\n",
    "    \"\"\"检查特定的已知乱码模式。\"\"\"\n",
    "    patterns = [\n",
    "        re.compile(r\"dy Woy papeo\"),\n",
    "        re.compile(r\"wOD AojLMW ATH\"),\n",
    "        # 可以在这里添加更多你发现的乱码模式\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        if pattern.search(text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_low_quality(element, text_length_threshold=20, alphanum_ratio_threshold=0.6):\n",
    "    \"\"\"\n",
    "    应用一系列规则来判断一个文档元素是否是低质量的。\n",
    "    \n",
    "    返回: (is_low_quality: bool, reason: str)\n",
    "    \"\"\"\n",
    "    text = element.text\n",
    "    \n",
    "    # 规则 1: 按元素类别过滤，我们只想要有意义的文本块。\n",
    "    if element.category not in ['NarrativeText', 'Title', 'ListItem', 'Table']:\n",
    "        return True, f\"Rejected category: '{element.category}'\"\n",
    "\n",
    "    # 规则 2: 文本太短，没有意义。\n",
    "    if not text or len(text.strip()) < text_length_threshold:\n",
    "        return True, f\"Text shorter than threshold ({text_length_threshold} chars)\"\n",
    "\n",
    "    # 规则 3: 字母和数字的比例过低。\n",
    "    alphanum_count = len(re.findall(r'[a-zA-Z0-9]', text))\n",
    "    total_count = len(text)\n",
    "    if total_count == 0:\n",
    "        return True, \"Empty text content\"\n",
    "    \n",
    "    ratio = alphanum_count / total_count\n",
    "    if ratio < alphanum_ratio_threshold:\n",
    "        return True, f\"Alphanum ratio too low ({ratio:.2f} < {alphanum_ratio_threshold})\"\n",
    "\n",
    "    # 规则 4: 包含已知的乱码模式。\n",
    "    if contains_garbled_patterns(text):\n",
    "        return True, \"Contains known garbled pattern\"\n",
    "\n",
    "    return False, \"High quality\"\n",
    "\n",
    "print(\"✅ Corrected cleaning functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 3: 分析并过滤元素\n",
    "\n",
    "现在我们遍历所有提取出的元素，应用我们的清洗函数，并查看哪些内容被丢弃了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing and Filtering PDF Content ---\n",
      "Iterating through all elements to find and analyze low-quality text...\n",
      "--- Analysis Complete ---\n",
      "Total elements processed: 617\n",
      "Elements kept: 257\n",
      "Elements discarded: 360\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Analyzing and Filtering PDF Content ---\")\n",
    "print(\"Iterating through all elements to find and analyze low-quality text...\")\n",
    "\n",
    "kept_elements = []\n",
    "discarded_elements = []\n",
    "\n",
    "if elements:\n",
    "    for i, element in enumerate(elements):\n",
    "        is_bad, reason = is_low_quality(element)\n",
    "\n",
    "        if is_bad:\n",
    "            discarded_elements.append({\n",
    "                \"index\": i,\n",
    "                \"text\": element.text,\n",
    "                \"reason\": reason,\n",
    "                \"category\": element.category\n",
    "            })\n",
    "        else:\n",
    "            kept_elements.append(element)\n",
    "\n",
    "    print(f\"--- Analysis Complete ---\")\n",
    "    print(f\"Total elements processed: {len(elements)}\")\n",
    "    print(f\"Elements kept: {len(kept_elements)}\")\n",
    "    print(f\"Elements discarded: {len(discarded_elements)}\")\n",
    "\n",
    "else:\n",
    "    print(\"Cannot analyze, no elements were extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 4: 检查被丢弃内容的样本\n",
    "\n",
    "这可以帮助我们验证我们的启发式规则是否有效，或者是否过于严格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20 Examples of Discarded Elements ---\n",
      "- Index: 0\n",
      "  Category: Header\n",
      "  Reason: Rejected category: 'Header'\n",
      "  Text: Received: 10 February 2016...\n",
      "- Index: 1\n",
      "  Category: Header\n",
      "  Reason: Rejected category: 'Header'\n",
      "  Text: Revised: 15 May 2017...\n",
      "- Index: 2\n",
      "  Category: Header\n",
      "  Reason: Rejected category: 'Header'\n",
      "  Text: Accepted: 24 May 2017...\n",
      "- Index: 4\n",
      "  Category: UncategorizedText\n",
      "  Reason: Rejected category: 'UncategorizedText'\n",
      "  Text: F I E L D R E P O RT...\n",
      "- Index: 5\n",
      "  Category: Title\n",
      "  Reason: Text shorter than threshold (20 chars)\n",
      "  Text: WILEY...\n",
      "- Index: 9\n",
      "  Category: Title\n",
      "  Reason: Text shorter than threshold (20 chars)\n",
      "  Text: Correspondence...\n",
      "- Index: 11\n",
      "  Category: Title\n",
      "  Reason: Text shorter than threshold (20 chars)\n",
      "  Text: Abstract...\n",
      "- Index: 13\n",
      "  Category: Title\n",
      "  Reason: Text shorter than threshold (20 chars)\n",
      "  Text: K E YW O R D S...\n",
      "- Index: 15\n",
      "  Category: UncategorizedText\n",
      "  Reason: Rejected category: 'UncategorizedText'\n",
      "  Text: 1...\n",
      "- Index: 16\n",
      "  Category: Title\n",
      "  Reason: Text shorter than threshold (20 chars)\n",
      "  Text: INTRODUCTION...\n",
      "- Index: 25\n",
      "  Category: UncategorizedText\n",
      "  Reason: Rejected category: 'UncategorizedText'\n",
      "  Text: wileyonlinelibrary.com/journal/rob...\n",
      "- Index: 26\n",
      "  Category: Footer\n",
      "  Reason: Rejected category: 'Footer'\n",
      "  Text: © 2017 Wiley Periodicals, Inc. ] 169...\n",
      "- Index: 27\n",
      "  Category: UncategorizedText\n",
      "  Reason: Rejected category: 'UncategorizedText'\n",
      "  Text: ”...\n",
      "- Index: 28\n",
      "  Category: Title\n",
      "  Reason: Text shorter than threshold (20 chars)\n",
      "  Text: | WILEY...\n",
      "- Index: 29\n",
      "  Category: Header\n",
      "  Reason: Rejected category: 'Header'\n",
      "  Text: 170...\n",
      "- Index: 36\n",
      "  Category: UncategorizedText\n",
      "  Reason: Rejected category: 'UncategorizedText'\n",
      "  Text: • three different driving strategies, allowing intervention or supervi-...\n",
      "- Index: 43\n",
      "  Category: Header\n",
      "  Reason: Rejected category: 'Header'\n",
      "  Text: PAOLILLO ET AL....\n",
      "- Index: 54\n",
      "  Category: UncategorizedText\n",
      "  Reason: Rejected category: 'UncategorizedText'\n",
      "  Text: diy twos, popeojumog *Z \"8102 “L96F9SSI...\n",
      "- Index: 55\n",
      "  Category: Header\n",
      "  Reason: Rejected category: 'Header'\n",
      "  Text: up) Sueyrag £q 1€£17°44/Z00 1°01 /Op/wOD AojLMW ATH UO Axeaq}] aUL|UE AdqEA4 “(eENg) J...\n",
      "- Index: 56\n",
      "  Category: UncategorizedText\n",
      "  Reason: Rejected category: 'UncategorizedText'\n",
      "  Text: zsdi) suonipuo pur sway. aip 99g [$Z0Z/S0/80]...\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 20 Examples of Discarded Elements ---\")\n",
    "if discarded_elements:\n",
    "    for item in discarded_elements[:20]: # 打印前20个例子\n",
    "        print(f\"- Index: {item['index']}\")\n",
    "        print(f\"  Category: {item['category']}\")\n",
    "        print(f\"  Reason: {item['reason']}\")\n",
    "        print(f\"  Text: {item['text'][:200].strip()}...\") # 打印摘要\n",
    "else:\n",
    "    print(\"No elements were discarded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Examples of KEPT Elements ---\n",
      "--------------------\n",
      "Original Index: 3 | Category: NarrativeText\n",
      "Text Snippet: DOI: 10.1002/rob.21731...\n",
      "--------------------\n",
      "Original Index: 6 | Category: Title\n",
      "Text Snippet: Autonomous car driving by a humanoid robot...\n",
      "--------------------\n",
      "Original Index: 7 | Category: Title\n",
      "Text Snippet: Antonio Paolillo1,2 Pierre Gergondet2 Andrea Cherubini1 Marilena Vendittelli3 Abderrahmane Kheddar1,2...\n",
      "--------------------\n",
      "Original Index: 8 | Category: NarrativeText\n",
      "Text Snippet: 1CNRS-UMLIRMM,Montpellier,France 2CNRS-AISTJRLUMI3218/RL,Tsukuba,Japan 3DIAG,SapienzaUniversitàdiRoma,Roma,Italy...\n",
      "--------------------\n",
      "Original Index: 10 | Category: NarrativeText\n",
      "Text Snippet: AntonioPaolillo,CNRS-UMLIRMM161Rue Ada,34090Montpellier. Email:paolillo@lirmm.fr...\n"
     ]
    }
   ],
   "source": [
    "if kept_elements:\n",
    "        print(\"\\n\\n--- Examples of KEPT Elements ---\")\n",
    "        for i, element in enumerate(kept_elements[:5]): # 最多显示5个\n",
    "            print(\"-\" * 20)\n",
    "            # 在原始列表中找到它的索引，方便对比\n",
    "            original_index = -1\n",
    "            try:\n",
    "                original_index = elements.index(element)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            print(f\"Original Index: {original_index} | Category: {element.category}\")\n",
    "            print(f\"Text Snippet: {element.text[:300]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
